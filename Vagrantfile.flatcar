# -*- mode: ruby -*-
# vi: set ft=ruby :

$script = <<SCRIPT
#
# Nomad 1.x required due to Nomad jobs manifests
#
echo "Installing Nomad..."
sudo mkdir -p /etc/nomad.d /etc/nomad /opt/nomad/data/ /etc/consul.d
# Error due to Flatcar default filesystems permissons restrictions
#nomad -autocomplete-install

# Netdata registration as Consul service
(
cat <<-EOF
{
  "service": {
    "name": "netdata",
    "address": "172.17.0.1",
    "port": 19999,
    "tags": ["monitoring","prometheus"],
    "checks": [
      {
        "http":     "http://localhost:19999/api/v1/allmetrics",
        "interval": "10s"
      }
    ]
  }
}
EOF
) | sudo tee /etc/consul.d/netdata.json

# Enable and start Netdata systemd service
sudo systemctl enable netdata.service
sudo systemctl start netdata

# Node exporter registration as Consul service
(
cat <<-EOF
{
  "service": {
    "name": "node-exporter",
    "address": "172.17.0.1",
    "port": 9100,
    "tags": ["monitoring","prometheus"],
    "checks": [
      {
        "http":     "http://localhost:9100/health",
        "interval": "10s"
      }
    ]
  }
}
EOF
) | sudo tee /etc/consul.d/node-exporter.json

# cAdvisor registration as Consul service
(
cat <<-EOF
{
  "service": {
    "name": "cadvisor",
    "port": 8080,
    "tags": ["monitoring"],
    "checks": [
      {
        "http":     "http://localhost:8080",
        "interval": "10s"
      }
    ]
  }
}
EOF
) | sudo tee /etc/consul.d/cadvisor.json

# cAdvisor service systemd startup script
(
cat <<-EOF
[Unit]
Description=cAdvisor containers monitoring from Google
Requires=docker.service
After=docker.service

[Service]
Type=simple
User=root
Group=root
# Default port is 8080
ExecStart=/opt/bin/cadvisor
Restart=always

[Install]
WantedBy=multi-user.target
EOF
) | sudo tee /etc/systemd/system/cadvisor.service

# Enable and start cAdvisor systemd service
sudo systemctl enable cadvisor.service
sudo systemctl start cadvisor

# Consul service systemd startup script
(
cat <<-EOF
[Unit]
Description=consul agent
Requires=network-online.target
After=network-online.target

[Service]
Restart=on-failure
ExecStart=/opt/bin/consul agent -dev -client=0.0.0.0 -config-dir=/etc/consul.d
ExecReload=/bin/kill -HUP $MAINPID
StandardOutput=journal+console
StandardError=journal+console

[Install]
WantedBy=multi-user.target

EOF
) | sudo tee /etc/systemd/system/consul.service

# Enable and start Consul systemd service
sudo systemctl enable consul.service
sudo systemctl start consul

# Nomad configuration
(
cat <<-EOF
data_dir  = "/opt/nomad/data/"
bind_addr = "0.0.0.0"
plugin "docker" {
  config {
    volumes {
      enabled = true
    }
  }
}

EOF
) | sudo tee /etc/nomad/config.hcl

# Nomad service systemd startup script
(
cat <<-EOF
[Unit]
Description=nomad dev agent
Requires=network-online.target
After=network-online.target

[Service]
Environment=PATH=/opt/bin:/usr/sbin:/usr/bin:/sbin:/bin
Restart=on-failure
ExecStart=/opt/bin/nomad agent -dev-connect -config=/etc/nomad/config.hcl
ExecReload=/bin/kill -HUP $MAINPID
StandardOutput=journal+console
StandardError=journal+console

[Install]
WantedBy=multi-user.target

EOF
) | sudo tee /etc/systemd/system/nomad.service

# Enable and start Nomad systemd service
sudo systemctl enable nomad.service
sudo systemctl start nomad

echo "Setting up iptable to forward dns request to consul..."
sudo iptables -t nat -A PREROUTING -p udp -m udp --dport 53 -j REDIRECT --to-ports 8600
sudo iptables -t nat -A PREROUTING -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 8600
sudo iptables -t nat -A OUTPUT -d localhost -p udp -m udp --dport 53 -j REDIRECT --to-ports 8600
sudo iptables -t nat -A OUTPUT -d localhost -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 8600

echo "Pulling Docker images"

if [ -n "$DOCKERHUBID" ] && [ -n "$DOCKERHUBPASSWD" ]; then
  echo "Login to Docker Hub as $DOCKERHUBID"
  if ! echo "$DOCKERHUBPASSWD" | sudo docker login --username "$DOCKERHUBID" --password-stdin; then
    echo 'Error login to Docker Hub'
    exit 2
  fi
fi

find /tmp/jobs /tmp/samples/nginx -maxdepth 1 -type f -name '*.hcl' | xargs grep -E 'image\s*=\s*' | awk '{print $NF}' | sed -e 's/"//g' -e 's/:demo//' | while read j; do
  echo "Pulling $j Docker image"
  if ! sudo docker pull $j >/dev/null; then
    echo "Exiting"
    exit 1
  fi
  if ! echo "$j" | grep -q ':'; then
    sudo docker tag "$j":latest "$j":demo
  fi
done
if [ $? -ne 0 ]; then
  exit 1
fi

if [ -n "$DOCKERHUBID" ] && [ -n "$DOCKERHUBPASSWD" ]; then
  echo "Logout from Docker Hub as $DOCKERHUBID"
  if ! sudo docker logout; then
    echo 'Error logging out from Docker Hub'
  fi
fi

echo "Installing Grafana stack..."

until nomad status
do
  echo "Waiting nomad to be ready...."
  sleep 3
done

# Handle all Nomad job files one at a time
# Use the naming of Nomad job files to determine scheduling order of services
find /tmp/jobs /tmp/samples/nginx -maxdepth 1 -type f -name '*.hcl' | sort | while read j; do
  # Job can be successfully planed (enough resources left)
  svc=$(basename $j | sed -e 's/\.nomad\.hcl//' -e 's/^[0-9][0-9]-//')
  if nomad plan $j | grep -Eq 'All tasks successfully allocated'; then
    echo "Scheduling $svc"
    nomad run $j
  else
    echo "Error can not schedule $svc"
  fi
done

# Configuring host DNS to use Consul for resolving
# `.consul` domain name queries
#
# Note that this requires the 2 first iptables
# commands above to be activated
#
# See: https://learn.hashicorp.com/tutorials/consul/dns-forwarding
#
# Full DNS capability of host machine requires local DNS as well
# as CloudFlare or Google
#
echo "Configuring DNS..."
EXTERNALDNS=${EXTERNALDNS:-"1.1.1.1"}
sudo sed -i -e "s/#DNS=/DNS=127.0.0.1 ${EXTERNALDNS}/" -e 's/#Domains=/Domains=~consul/' /etc/systemd/resolved.conf
sudo systemctl restart systemd-resolved

while [ "$(dig +short loki.service.dc1.consul)" == "" ]; do
  echo "Waiting Loki to be ready...."
  sleep 10
done

# Configuring and starting system Promtail
#
# This needs to be done after Loki service
# has been launched in Docker container
# by Nomad job scheduling
#
(
cat <<-EOF
server:
  http_listen_port: 9080
  grpc_listen_port: 0
positions:
  filename: /tmp/positions.yaml
client:
  url: http://$(dig +short loki.service.dc1.consul):3100/loki/api/v1/push
scrape_configs:
  - job_name: nginx
    static_configs:
    - targets:
        - localhost
      labels:
        job: nginx
        env: production
        __path__: /tmp/nginx-logs/*.log
  - job_name: journal
    journal:
      max_age: 1h
      path: /var/log/journal
      labels:
        job: systemd
        env: production
    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'
EOF
) | sudo tee /etc/promtail/promtail.yml

(
cat <<-EOF
[Unit]
Description=Promtail service
After=network.target
[Service]
Type=simple
ExecStart=/opt/bin/promtail -config.file /etc/promtail/promtail.yml
[Install]
WantedBy=multi-user.target
EOF
) | sudo tee /etc/systemd/system/promtail.service

sudo systemctl enable promtail.service
sudo systemctl start promtail

sudo chmod 755 /tmp/samples/nginx/load_gen.sh

# Nginx load generator
(
cat <<-EOF
  [Unit]
  Description=Nginx load generator
  Requires=network-online.target promtail.service
  After=network-online.target promtail.service

  [Service]
  Environment=PATH=/opt/bin:/usr/sbin:/usr/bin:/sbin:/bin
  Restart=on-failure
  ExecStart=/tmp/samples/nginx/load_gen.sh
  ExecReload=/bin/kill -HUP $MAINPID

  [Install]
  WantedBy=multi-user.target
EOF
) | sudo tee /etc/systemd/system/nginx-load-gen.service
sudo systemctl enable nginx-load-gen.service
sudo systemctl start nginx-load-gen

SCRIPT

Vagrant.configure(2) do |config|
  #
  # Get local host timezone
  # PLEASE NOTE: the result can be tricked if you have any VPN
  # or system-wide HTTP proxy configured on your Vagrant host
  #
  # PLEASE ALSO NOTE: the service at ipapi.co is protected from DDos
  # by CloudFlare and therefore it might happen that you'll be denied
  # to query the API too often if you respawn your environment too often
  #
  # Set default to your timezone
  ltz = 'Europe/Paris'

  # There is no clean way to set the ltz variable only in a trigger up
  # case for a dirty way see:
  # https://gist.github.com/jamiejackson/4ec92bef2e148d58d207b15f2c92b066
#  config.trigger.before :up do |trigger|
#    trigger.info = "Retrieving host timezone"
#    trigger.ruby do |env,machine|
      puts "Retrieving host timezone"
      require 'uri'
      require 'net/http'
      require 'json'

      begin
        uri = URI('https://ipapi.co/timezone')
        res = Net::HTTP.get_response(uri)
        if res.is_a?(Net::HTTPSuccess)
          ltz = res.body
          puts "Timezone set from ipapi.co to: " + ltz
        elsif res.is_a?(Net::HTTPTooManyRequests)
          puts "Unable to get timezone from ipapi.co: trying fallback"
          uri = URI('https://ipapi.co/json')
          res = Net::HTTP.get_response(uri)
          if res.is_a?(Net::HTTPSuccess)
            jsres = JSON.parse(res.body)
            if ! jsres['timezone'].to_s.strip.empty?
              ltz = jsres['timezone']
              puts "Timezone set from ipapi.co fallback to: " + ltz
            else
              puts "Unable to get timezone from ipapi.co fallback. Using default: " + ltz
            end
          elsif res.is_a?(Net::HTTPTooManyRequests)
            puts "Unable to get timezone from ipapi.co fallback. Using default: " + ltz
          else
            puts "Unknown response received from ipapi.co: "
            puts res
    #        abort("Exiting")
          end
        else
          puts "Unknown response received from ipapi.co: "
          puts res
    #      abort("Exiting")
        end
      rescue => e
        puts e
        abort("Exiting")
      end
#    end
#  end

  config.vm.box = "obourdon/flatcar-linux-observability"
  config.vm.box_version = "2765.2.5"
  config.vm.hostname = "flatcar-nomad"
  # Flatcar Linux does not support VirtualBox Guest Additions therefore the copy
  config.vm.provision "file", source: "./jobs", destination: "/tmp/jobs"
  config.vm.provision "file", source: "./samples", destination: "/tmp/samples"
  # Set the timezone the same as the host so that metrics & logs ingested have the right timestamp.
  config.vm.provision :shell, :inline => "echo setting Timezone to " + ltz + "; sudo timedatectl set-timezone " + ltz, run: "always"
  config.vm.provision "shell", inline: $script, env: {"EXTERNALDNS"=>ENV['EXTERNALDNS'], "DOCKERHUBID"=>ENV['DOCKERHUBID'], "DOCKERHUBPASSWD"=>ENV['DOCKERHUBPASSWD']}, privileged: false

  # Expose the nomad api and ui to the host
  config.vm.network "forwarded_port", guest: 4646, host: 4646
  # consul
  config.vm.network "forwarded_port", guest: 8500, host: 8500
  # grafana
  config.vm.network "forwarded_port", guest: 3000, host: 3000
  # prometheus
  config.vm.network "forwarded_port", guest: 9090, host: 9090
  # loki
  config.vm.network "forwarded_port", guest: 3100, host: 3100
  # promtail
  config.vm.network "forwarded_port", guest: 3200, host: 3200
  # tns app
  config.vm.network "forwarded_port", guest: 8001, host: 8001
  # Nginx
  config.vm.network "forwarded_port", guest: 8888, host: 8888
  # cAdvisor
  config.vm.network "forwarded_port", guest: 8080, host: 8080
  # Netdata
  config.vm.network "forwarded_port", guest: 19999, host: 19999

  # Increase memory for Parallels Desktop
  config.vm.provider "parallels" do |p, o|
    p.memory = "4096"
  end

  # Increase memory for Virtualbox
  config.vm.provider "virtualbox" do |vb|
        vb.memory = "4096"
  end

  # Increase memory for VMware
  ["vmware_fusion", "vmware_workstation"].each do |p|
    config.vm.provider p do |v|
      v.vmx["memsize"] = "4096"
    end
  end
end
